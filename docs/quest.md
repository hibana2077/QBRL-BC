# 用量化分箱與非負CP張量分解打造可解釋且 CPU 可負擔的乳癌診斷模型——以 UCI Breast Cancer Wisconsin (Diagnostic) 資料集為例

QBTD‑BC: A Quantization‑Based Binning and Non‑Negative CP Tensor Decomposition Model for Interpretable and CPU‑Efficient Breast Cancer Diagnosis

---

## 1. 研究核心問題

在僅使用 CPU 的資源限制下，如何將連續特徵經量化分箱後形成的布林/非負特徵，透過\*\*非負 CP 張量分解（Nonnegative CP Decomposition, NCPD）\*\*萃取出少量、可直接對應到臨床特徵區間的「潛在模式」，並在乳癌良惡性分類上維持高準確度與良好校準度，同時提升模型可解釋性。 ([Frontiers][1], [kolda.net][2], [archive.ics.uci.edu][3])

---

## 2. 研究目標

1. 建立「量化分箱 → 建構三維張量 → 非負CP分解 → 因子轉規則/特徵 → 分類器」的完整 CPU 流程。 ([Frontiers][1], [kolda.net][2])
2. 系統性比較不同分箱策略（等寬、等頻、MDLP 監督式）對張量因子可讀性與模型效能的影響。 ([科學直接][4], [維基百科][5])
3. 以多種分類指標與校準指標（AUC、F1、Brier Score 等）全面評估模型，並使用 McNemar 檢定比較與基準模型差異。 ([維基百科][6], [rasbt.github.io][7])
4. 透過 Decision Curve Analysis（DCA）評估模型在臨床決策上的實際淨效益。 ([BioMed Central][8])

---

## 3. 貢獻與創新

* **張量分解導向的規則化解釋**：將分箱後的資料視為「樣本 × 特徵 × 區間」三維張量，以 NCPD 或布林張量分解擷取可讀的潛在模式，詮釋為「同時落在某些特徵區間的病例群」。 ([Frontiers][1], [Proceedings of Machine Learning Research][9])
* **低資源可重現**：全流程依賴 CPU 可行的演算法（NCPD 在小型資料上計算量極低），並公開所有設定、時間與記憶體用量。 ([Frontiers][1], [kolda.net][2])
* **分箱策略 × 張量分解的交互研究**：補足現有文獻多聚焦在連續特徵直接輸入黑盒模型的缺口，提供可讀性與效能兼顧的實證。 ([科學直接][4], [維基百科][5])
* **臨床價值評估**：結合 DCA，將模型轉譯成不同決策閾值下的淨效益，突顯研究的實務價值。 ([BioMed Central][8])

---

## 4. 方法設計

### 4.1 資料與問題設定

* **資料集**：UCI Breast Cancer Wisconsin (Diagnostic)，569 筆樣本、30 個特徵、二元標籤（惡性/良性）。 ([archive.ics.uci.edu][3], [archive.ics.uci.edu][10])

### 4.2 前處理

1. 檢查缺失值與離群值（此資料集理論上無缺失，但流程需記錄）。
2. 以 Stratified nested k-fold CV 分割資料，外層估計泛化誤差、內層選超參數（分箱數、張量秩 R、正則化係數等）。此為常見做法，無特定引用需求。

### 4.3 量化分箱（Discretization）

* **無監督式**：等寬、等頻分箱。 ([科學直接][4], [sci2s.ugr.es][11])
* **監督式**：使用 MDLP（Fayyad & Irani, 1993）以資訊增益選擇切點。 ([科學直接][4], [維基百科][5])
* 以內層 CV 依「規則化後的可讀性（如因子稀疏度、條件數）＋效能」選最佳策略。

### 4.4 建構三維張量

* 維度設計：

  * **樣本維（N）**：569。
  * **特徵維（F）**：30。
  * **分箱維（B）**：每個特徵的分箱區間（可統一上限，如 5–8 個 bin）。
* 張量元素：若樣本 i 的特徵 j 落在 bin k，則 X(i,j,k)=對應值（0/1 或原始分箱權重）。
* 亦可堆疊成「樣本 × 特徵群 × 分箱」或加入其他維度（如群集後的特徵群），視實驗複雜度調整。

### 4.5 非負 CP 張量分解（NCPD）

* 將張量分解為 R 個 rank-one 非負組件（A⊗B⊗C 的和），每個組件對應一組「樣本子集 × 特徵子集 × 區間子集」的關聯。 ([Frontiers][1], [kolda.net][2])
* 透過 L1/稀疏性約束，使每個組件只涉及少量特徵與區間，提升可讀性。 ([Frontiers][1])
* （備案）若想直接得到布林規則，可改用**布林張量分解（Boolean Tensor Decomposition）**，其遵循布林代數且產生二元因子，具高度可解釋性。 ([Proceedings of Machine Learning Research][9], [Proceedings of Machine Learning Research][12])

### 4.6 因子轉規則／特徵

* 將每個組件中較高權重的「特徵–區間」對組合成 IF–THEN 規則（如：`if radius_mean∈[a,b] AND texture_worst∈[c,d] then Factor_3=1`）。
* 產生的 R 維「因子啟動分數」當作新特徵，輸入輕量分類器（邏輯迴歸、隨機森林）完成預測。

### 4.7 基準模型（Baselines）

* 邏輯迴歸（L1/L2）、決策樹／隨機森林、k-NN、SVM（CPU 版），與本研究流程對照。
* 可額外比較 NMF（非負矩陣分解）或 RuleFit 等其他可解釋方法（選用即可）。

### 4.8 穩健性與穩定度

* 透過 bootstrap 或 repeated CV 重複整個流程，計算：

  * 因子對（或規則對）間的 **Jaccard 相似度** 以評估穩定性。
  * 指標的信賴區間（95% CI）。
    （Jaccard 與 bootstrap 為一般統計慣例，可不特別引用。）

---

## 5. 實驗指標與評估計畫

### 5.1 分類效能

* **AUC(ROC)、F1、Accuracy、Balanced Accuracy**：基本分類表現。
* **Brier Score**：機率預測誤差（均方差形式），檢視校準。 ([維基百科][6], [mclust-org.github.io][13])

### 5.2 校準與臨床價值

* **Calibration curve、Hosmer–Lemeshow 檢定**（可選）檢視機率校準。
* **Decision Curve Analysis (DCA)**：計算在各決策閾值下的 Net Benefit，評估臨床實用性。 ([BioMed Central][8], [PubMed][14], [PubMed][15])

### 5.3 可解釋性／複雜度

* 因子數（R）、每因子所涉特徵數、每因子所涉分箱數。
* 規則長度（條件數）、覆蓋率（support）與精確率（precision）。
* 主觀可讀性調查（若可接觸專家）。

### 5.4 統計檢定

* **McNemar Test**：比較本方法與基準模型在同一資料集上的錯誤分布差異。 ([rasbt.github.io][7], [維基百科][16])
* 主要指標（AUC、Brier 等）以 bootstrap 估計 95% CI。

### 5.5 資源消耗量

* 記錄訓練／推論時間、記憶體占用，證明 CPU 友善。

### 5.6 實驗流程

1. **Nested CV**：外層 k-fold（例：k=10）估計泛化；內層調 λ（稀疏性）、R（秩）、分箱策略等。
2. **Ablation Study**：

   * 不做監督式分箱 vs. 做監督式分箱的差異。
   * NCPD vs. BTD（布林分解）比較可讀性與效能。
3. **穩定度分析**：多隨機種子重複流程，計算因子集合的 Jaccard 相似度。

---

## 6. 備用技術方案（若張量分解效果不佳或實作困難）

* **NMF + 互動項設計**：將「樣本 × (特徵×分箱)」矩陣做 NMF，得到部件式解釋，再接分類器。 ([stat.ucla.edu][17])
* **Boolean Matrix Factorization**：降階到矩陣層級，仍可得到布林規則集。 ([Proceedings of Machine Learning Research][9])

[1]: https://www.frontiersin.org/journals/applied-mathematics-and-statistics/articles/10.3389/fams.2024.1287074/full?utm_source=chatgpt.com "Sparseness-constrained nonnegative tensor factorization for ..."
[2]: https://www.kolda.net/publication/TensorReview.pdf?utm_source=chatgpt.com "[PDF] Tensor Decompositions and Applications"
[3]: https://archive.ics.uci.edu/datasets?search=Breast+Cancer+Wisconsin+%28Original%29&utm_source=chatgpt.com "Datasets - UCI Machine Learning Repository"
[4]: https://www.sciencedirect.com/topics/computer-science/supervised-discretization?utm_source=chatgpt.com "Supervised Discretization - an overview | ScienceDirect Topics"
[5]: https://en.wikipedia.org/wiki/Discretization_of_continuous_features?utm_source=chatgpt.com "Discretization of continuous features - Wikipedia"
[6]: https://en.wikipedia.org/wiki/Brier_score?utm_source=chatgpt.com "Brier score - Wikipedia"
[7]: https://rasbt.github.io/mlxtend/user_guide/evaluate/mcnemar/?utm_source=chatgpt.com "McNemar's test for classifier comparisons - mlxtend - GitHub Pages"
[8]: https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-019-0064-7?utm_source=chatgpt.com "A simple, step-by-step guide to interpreting decision curve analysis"
[9]: https://proceedings.mlr.press/v80/rukat18a/rukat18a.pdf?utm_source=chatgpt.com "[PDF] Probabilistic Boolean Tensor Decomposition"
[10]: https://archive.ics.uci.edu/dataset/17/breast%2Bcancer%2Bwisconsin%2Bdiagnostic?utm_source=chatgpt.com "Breast Cancer Wisconsin (Diagnostic) - UCI Machine Learning ..."
[11]: https://sci2s.ugr.es/keel/pdf/algorithm/articulo/liu1-2.pdf?utm_source=chatgpt.com "[PDF] Discretization: An Enabling Technique"
[12]: https://proceedings.mlr.press/v80/rukat18a.html?utm_source=chatgpt.com "Probabilistic Boolean Tensor Decomposition"
[13]: https://mclust-org.github.io/mclust/reference/BrierScore.html?utm_source=chatgpt.com "Brier score to assess the accuracy of probabilistic predictions"
[14]: https://pubmed.ncbi.nlm.nih.gov/17099194/?utm_source=chatgpt.com "Decision curve analysis: a novel method for evaluating prediction ..."
[15]: https://pubmed.ncbi.nlm.nih.gov/33676020/?utm_source=chatgpt.com "Decision curve analysis to evaluate the clinical benefit of prediction ..."
[16]: https://en.wikipedia.org/wiki/McNemar%27s_test?utm_source=chatgpt.com "McNemar's test"
[17]: https://www.stat.ucla.edu/~ywu/research/documents/BOOKS/NonnegativeMatrix.pdf?utm_source=chatgpt.com "[PDF] Nonnegative Matrix and Tensor Factorizations"
